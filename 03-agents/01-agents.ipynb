{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3546018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcea1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiplies a and b\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "name='multiply' description='Multiplies a and b' args_schema=<class 'langchain_core.utils.pydantic.multiply'> func=<function multiply at 0x000001BF8C013D80>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b\"\"\"\n",
    "    return int(a) + int(b)\n",
    "\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) ->int:\n",
    "    \"\"\"Subtracts b from a\"\"\"\n",
    "    return int(a) - int(b)\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b\"\"\"\n",
    "    return int(a) * int(b)\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "\n",
    "tools = [add, subtract, multiply]\n",
    "\n",
    "print(multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48061b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='search-tool' description='Lookup things online' args_schema=<class '__main__.SearchInput'> func=<function search at 0x0000018472E1E200>\n",
      "{'query': {'description': 'should be a search query', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "    \n",
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput)\n",
    "def search(q: str) -> str:\n",
    "    \"\"\"Lookup things online\"\"\"\n",
    "    return \"LangChain\"\n",
    "\n",
    "print(search)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3467e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b\"\"\"\n",
    "    return int(a) * int(b)\n",
    "\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    \"\"\"Multiply two integers\"\"\"\n",
    "    a: int = Field(..., description=\"First Number\")\n",
    "    b: int = Field(..., description=\"Second Number\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461d7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='custom-multiply', description='Multiply 2 numbers', args_schema=<class '__main__.MultiplyInput'>, func=<function mymultiply at 0x00000184742EA200>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "mytool = StructuredTool.from_function(\n",
    "    name=\"custom-multiply\",\n",
    "    func=mymultiply,\n",
    "    args_schema=MultiplyInput,\n",
    "    description=\"Multiply 2 numbers\"\n",
    ")\n",
    "\n",
    "mytool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2bb7ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Understanding the New $100000 H-1B Fee and its Effect on U.S. ...',\n",
       "  'url': 'https://www.employmentlawworldview.com/understanding-the-new-100000-h-1b-fee-and-its-effect-on-u-s-employers/',\n",
       "  'content': 'On Friday, September 19, 2025, President Trump issued a Proclamation entitled “Restrictions on Entry of Certain Nonimmigrant Workers” that imposes a $100,000 fee for most new H-1B visa petitions and restricts the ability of certain H-1B visa holders to enter the United States.The H-1B visa is the workhorse of the U.S. immigration system, currently used by approximately three-quarters of a million U.S. workers to provide high-skilled labor in “specialty occupations” requiring at least a related',\n",
       "  'score': 0.8029425},\n",
       " {'title': 'H-1B FAQ - USCIS',\n",
       "  'url': 'https://www.uscis.gov/newsroom/alerts/h-1b-faq',\n",
       "  'content': 'On Friday, Sept. 19, 2025, President Donald J. Trump signed a Proclamation, \"Restriction on Entry of Certain Nonimmigrant Workers,\" that took an important, initial, and incremental step to reform the H-1B visa program to curb abuses and protect American workers.\\n\\nThis Proclamation:',\n",
       "  'score': 0.7089592},\n",
       " {'title': 'Fact Sheet: President Donald J. Trump Suspends the Entry of ...',\n",
       "  'url': 'https://www.whitehouse.gov/fact-sheets/2025/09/fact-sheet-president-donald-j-trump-suspends-the-entry-of-certain-alien-nonimmigrant-workers/',\n",
       "  'content': 'Today, President Donald J. Trump signed a Proclamation to restrict the entry into the United States of certain H-1B aliens as nonimmigrant workers, requiring a $100,000 payment to accompany or supplement H-1B petitions for new applications to curb abuses that displace U.S. workers and undermine national security. [...] The Proclamation restricts entry for aliens as nonimmigrants to perform services in specialty occupations in the H-1B program unless their petition is accompanied by a $100,000 payment.\\n   It directs the Secretary of Homeland Security to restrict approvals for petitions from aliens that are currently outside the United States that are not accompanied by the payment, and allows case-by-case exemptions if in the national interest. [...] American IT workers have even been reportedly forced to train their foreign replacements under nondisclosure agreements.\\n   The H-1B program is creating disincentives for future American workers to choose STEM careers, which threatens our national security.\\n   President Trump is imposing higher costs on companies seeking to use the H-1B program in order to address the abuse of the program, stop the undercutting of wages, and protect our national security.\\n\\nPrioritizing American Workers',\n",
       "  'score': 0.7036111},\n",
       " {'title': '$100000 H-1B Fee Causes Chaos, Likely Unaffordable for Many ...',\n",
       "  'url': 'https://www.americanimmigrationcouncil.org/blog/100000-h1b-fee-unaffordable-companies/',\n",
       "  'content': 'A White House fact sheet issued on September 19 also said that the proclamation restricts entry for H-1B workers “unless their petition is accompanied by a $100,000 payment.” Some U.S. companies notified their H-1B workers to return to the United States immediately.\\n\\nTrump administration reaction after the announcement [...] As written, the proclamation prohibited the entry of noncitizens to the United States in H-1B status, after 12:01 am Eastern Time on September 21, 2025 (the deadline) if the employer that had filed an H-1B petition for them had not paid a $100,000 fee. The restriction will expire in 12 months, unless extended. The proclamation also would restrict USCIS adjudication of H-1B petitions filed on behalf of noncitizens abroad if the petitioner had not paid the fee. [...] Business and the Workforce\\n    September 24, 2025 \\n\\nPresident Donald Trump announced that his administration will impose a $100,000 fee on new H-1B…\\n\\nRead More\\n\\nImage 11: Post Image\\n\\n### Trump’s Immigration Actions Are Taking a Toll on Local Economies – Here’s What the Data Says So Far\\n\\n   Business and the Workforce\\n    August 27, 2025 \\n\\nSeven months into President Trump’s term, immigration enforcement operations continue to ramp up, and the…\\n\\nRead More\\n\\nImage 12: Post Image',\n",
       "  'score': 0.64639384},\n",
       " {'title': 'Trump Administration Signs Proclamation Declaring New $100,000 ...',\n",
       "  'url': 'https://www.boundless.com/blog/trump-administration-to-propose-new-100000-fee-for-h-1b-visa-applications/',\n",
       "  'content': 'Image 1: Trump H1b fee 100000\\nPresident Donald Trump has signed a proclamation that will require a $100,000 application fee for H-1B visas, in what experts are calling one of the most dramatic changes to the skilled worker program in decades. The proclamation went into effect on September 21, 2025. [...] Increased Scrutiny: The administration states these measures are intended to protect U.S. workers and crack down on perceived misuse of the H-1B lottery system. [...] The Department of State (DOS) released an alert clarifying that the new $100,000 fee does not apply to individuals who filed their H-1B petitions before September 21, 2025 and are currently seeking visa issuance and/or entry into the U.S.\\n\\n_Boundless can help you explore the EB-1A green card — a stable alternative to the unpredictable H-1B visa. See if you qualify._\\n\\nKey Changes Proposed\\n\\nThe proclamation outlines several sweeping changes:',\n",
       "  'score': 0.63316137}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "search_results = tavily_search_tool.invoke({\"query\": \"Give summary on H1B Restrictions issued by Trump\"})\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf8624dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content String : Hello! How can I assist you today?\n",
      "Tool Calls: []\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [tavily_search_tool, add, subtract, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke([HumanMessage(content=\"Hi\")])\n",
    "\n",
    "print(f\"Content String : {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3157e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content String : \n",
      "Tool Calls: [{'name': 'tavily_search_results_json', 'args': {'query': 'Trump H1B New Policy 2025 updates'}, 'id': 'call_aLeGekKGgJ5bXJU49c8SUheW', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_tools.invoke([HumanMessage(content=\"Tell me about Trump H1B New Policy (search for latest 2025 updates)\")])\n",
    "\n",
    "print(f\"Content String : {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "    for tool in tools:\n",
    "        if tool.name == tool_name:\n",
    "            return tool\n",
    "    \n",
    "    raise ValueError(f\"Tool with name {tool_name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95277997",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    You have to use these tools only, even if you can compute the response directly\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f5be972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\\nadd(a: int, b: int) -> int - Adds a and b\\nsubtract(a: int, b: int) -> int - Subtracts b from a\\nmultiply(a: int, b: int) -> int - Multiplies a and b', 'tool_names': 'tavily_search_results_json, add, subtract, multiply'}, template='\\n    Answer the following questions as best you can. You have access to the following tools:\\n\\n    {tools}\\n\\n    You have to use these tools only, even if you can compute the response directly\\n\\n    Use the following format:\\n\\n    Question: the input question you must answer\\n    Thought: you should always think about what to do\\n    Action: the action to take, should be one of [{tool_names}]\\n    Action Input: the input to the action\\n    Observation: the result of the action\\n    ... (this Thought/Action/Action Input/Observation can repeat N times)\\n    Thought: I now know the final answer\\n    Final Answer: the final answer to the original input question\\n\\n    Begin!\\n\\n    Question: {input}\\n    Thought: {agent_scratchpad}\\n')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import render_text_description\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template).partial(\n",
    "    tools = render_text_description(tools),\n",
    "    tool_names = \", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2dd1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    stop_sequences=[\"Observation\", \"\\nObservation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dede37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='multiply', tool_input='3, 4  \\n', log='To solve the expression \\\\(2 + 3 \\\\times 4\\\\), I need to remember the order of operations (PEMDAS/BODMAS), which prioritizes multiplication over addition.\\n\\nFirst, I will calculate \\\\(3 \\\\times 4\\\\) and then add 2 to the result.\\n\\nAction: multiply  \\nAction Input: 3, 4  \\n')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "\n",
    "intermediate_steps = []\n",
    "\n",
    "chain = {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: x[\"intermediate_steps\"]\n",
    "        } |prompt | llm | ReActSingleInputOutputParser()\n",
    "\n",
    "\n",
    "agent_action = chain.invoke({\n",
    "    \"input\": \"What is 2 + 3 multiplied by 4\",\n",
    "    \"intermediate_steps\": intermediate_steps\n",
    "})\n",
    "\n",
    "agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db5427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(AgentAction(tool='multiply', tool_input='3, 4  \\n', log='To solve the expression \\\\(2 + 3 \\\\times 4\\\\), I need to remember the order of operations (PEMDAS/BODMAS), which prioritizes multiplication over addition.\\n\\nFirst, I will calculate \\\\(3 \\\\times 4\\\\) and then add 2 to the result.\\n\\nAction: multiply  \\nAction Input: 3, 4  \\n'),\n",
       "  12)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_steps.append((agent_action, 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6859276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To solve the expression \\\\(2 + 3 \\\\times 4\\\\), I need to remember the order of operations (PEMDAS/BODMAS), which prioritizes multiplication over addition.\\n\\nFirst, I will calculate \\\\(3 \\\\times 4\\\\) and then add 2 to the result.\\n\\nAction: multiply  \\nAction Input: 3, 4  \\n\\nObservation: 12\\nThought: '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.format_scratchpad import  format_log_to_str\n",
    "\n",
    "format_log_to_str(intermediate_steps=intermediate_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7206419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='multiply', tool_input='3, 4  \\n', log='To solve the expression \\\\(2 + 3 \\\\times 4\\\\), I need to follow the order of operations, where multiplication comes before addition. First, I will multiply 3 by 4, and then I will add 2 to the result.\\n\\nAction: multiply  \\nAction Input: 3, 4  \\n')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_steps = []\n",
    "\n",
    "agent = {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"])\n",
    "        } |prompt | llm | ReActSingleInputOutputParser()\n",
    "\n",
    "\n",
    "agent_action = agent.invoke({\n",
    "    \"input\": \"What is 2 + 3 multiplied by 4\",\n",
    "    \"intermediate_steps\": intermediate_steps\n",
    "})\n",
    "agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "719205ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='add', tool_input='2, 12  \\n\\n', log='Now that I have multiplied 3 by 4 to get 12, I need to add 2 to this result.\\n\\nAction: add  \\nAction Input: 2, 12  \\n\\n')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_steps.append((agent_action, 12))\n",
    "\n",
    "agent_action = agent.invoke({\n",
    "    \"input\": \"What is 2 + 3 multiplied by 4\",\n",
    "    \"intermediate_steps\": intermediate_steps\n",
    "})\n",
    "agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "274a83fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': '14'}, log='I now know the final answer  \\nFinal Answer: 14')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_steps.append((agent_action, 14))\n",
    "\n",
    "agent_action = agent.invoke({\n",
    "    \"input\": \"What is 2 + 3 multiplied by 4\",\n",
    "    \"intermediate_steps\": intermediate_steps\n",
    "})\n",
    "agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b13e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9222eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from typing import List\n",
    "from langchain.tools import Tool\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "    for tool in tools:\n",
    "        if tool.name == tool_name:\n",
    "            return tool\n",
    "    \n",
    "    raise ValueError(f\"Tool with name {tool_name} not found\")\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    You have to use these tools only, even if you can compute the response directly\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "\"\"\"\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "tools = [tavily_search_tool, add, subtract, multiply]\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template).partial(\n",
    "    tools = render_text_description(tools),\n",
    "    tool_names = \", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    stop_sequences=[\"Observation\", \"\\nObservation\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142490e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.agents.format_scratchpad import  format_log_to_str\n",
    "\n",
    "intermediate_steps = []\n",
    "\n",
    "agent = {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"])\n",
    "        } |prompt | llm | ReActSingleInputOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e9e7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Step = tool='tavily_search_results_json' tool_input='Sivaprasad Valluru\"  \\n' log='I need to gather information about Sivaprasad Valluru. To do this, I will perform a search for his name to find reliable and comprehensive details.  \\nAction: tavily_search_results_json  \\nAction Input: \"Sivaprasad Valluru\"  \\n'\n",
      "Tool Selected = api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))\n",
      "Tool Inputs = Sivaprasad Valluru\"  \n",
      "\n",
      "Observation = [{'title': 'SivaPrasad - Learning why what when', 'url': 'https://www.learnagenticai.in/home/about-us#:~:text=SivaPrasad Valluru is a instructor,done contribution to Spring framework.', 'content': 'SivaPrasad Valluru is a instructor with 20 years of experince in IT . He has worked with Motorola, Alcatel Lucent and TechMahindra earlier. Now, he delivers corporate trainings. He has done contribution to Spring framework.', 'score': 0.9854}, {'title': 'SivaPrasad Valluru is a instructor with 20 years of ... - Instagram', 'url': 'https://www.instagram.com/p/CrYfQAZtUzh/', 'content': 'Image 1: Photo by Learn Why what when on April 23, 2023. He got certified as a instructor from Mulesoft and Pivotal and has delivered many certified trainings. More posts from learnwww_ Image 7: Do you want to learn Mule from an experienced and Mulesoft certified Instructor who makes complex concepts simple and easy to understand? Join the Live instructor led training on \"Mule 4, DataWeave and MCIA\" starting on May 8th. Enroll for the 11 INR course now Lwww.in Talk to instructor directly on his whatsapp +91 8088910831 ------------------------------------------------------ Follow us Facebook - facebook.com/LearnWhyWhenWhere/ Instagram - instagram.com/learnwww_/ ------------------------------------------------------- #beanexpert #kubernetes #dockerinstructor #docker #DataWeave #MulesoftCertified #mcia #LearnDockerOnline #learnmulesoft #learnwww #learndataweave Image 10: Photo by Learn Why what when on April 30, 2023.', 'score': 0.98187}, {'title': 'sivaprasad valluru - CACI International Inc', 'url': 'https://www.linkedin.com/in/sivaprasad-valluru-294b0528', 'content': 'sivaprasad valluru\\nCACI Federal Inc.\\nIrving, Texas, United States\\n58 connections, 59 followers\\n\\n\\nAbout\\n• Over all 14 years of IT experience with 7 years in SAP Fiori, 7 years on Portal/CE…\\n\\n\\nExperience\\nN/A\\n\\n\\nEducation\\nN/A', 'score': 0.97923}, {'title': 'SivaPrasad Valluru`s (ID-189657) - Courses', 'url': 'https://market.tutorialspoint.com/profile/sivaprasad_valluru', 'content': 'Use: **FREEDOM10** *   Certifications *   Courses ### Image 5 ### Courses (1) Image 7: Master Docker: In-Depth Course ### Courses (1) Image 11: Master Docker: In-Depth Course ##### Course Categories *   Development Courses *   Programming Courses *   Cyber Security Courses *   Marketing Courses *   Business Courses *   IT and Software Courses *   Lifestyle Courses *   Web Development Courses *   Office Productivity Courses *   Digital Marketing Courses *   WordPress Courses ##### Trending Courses *   Python Courses *   Java Courses *   DevOps Courses *   Deep Learning Courses *   Machine Learning Courses *   Digital Marketing Courses *   Blockchain Courses ##### Advanced Certifications *   Advanced Python Certification *   Cyber Security Advanced Certification ##### Certifications *   Courses *   Certifications *   Free Courses Image 17&kw=Video%20Courses,%20eBooks,%20Certifications,%20Learnig%20Paths,%20Self%20Learning,%20Buy%20Video%20Courses,%20University%20Courses,%20Corporate%20Training&p=https%3A%2F%2Fwww.tutorialspoint.com%2Fprofile%2Fsivaprasad_valluru&r=&lt=708&evt=pageLoad&sv=1&cdb=AQAQ&rn=241143)', 'score': 0.97485}, {'title': '2024 OCP Global Summit - Open Compute Project', 'url': 'https://www.opencompute.org/events/past-events/2024-ocp-global-summit', 'content': '| Welcome to OCP Global Summit | George Tchaparian (CEO) - Open Compute Project Foundation (OCP) | Video | Slides | | Accelerating AI: a Holistic- Open Approach - Presented by AMD | Forrest Norrod (Executive VP and General Manager- Data Center Solutions Business Group) - AMD | Video | Slides | | Addressing Future Thermal Challenges Driven by AI - Presented by Lenovo | Vinod Kamath (Distinguished Engineer ‚Äì Thermal - Isg Platform Development) - Lenovo Mark Luxford (Managing Director Liquid Cooling) - Vertiv Mike Sabotta (Solutions Architect For Cloud and HPC System Design) - Nvidia Cheng Chen (Thermal Engineer- Compute Hardware) - Meta Mario Zeng (VP of Cloud Service Provider) - Lenovo | Video | Slides |', 'score': 0.96226}]\n",
      "Intermediate Step = {format_log_to_str(intermediate_steps)}\n",
      "Agent Step = return_values={'output': 'Sivaprasad Valluru is an instructor with 20 years of experience in IT, having worked with companies like Motorola, Alcatel Lucent, and TechMahindra. He currently delivers corporate training and has contributed to the Spring framework. He is certified from Mulesoft and Pivotal.'} log='I have found relevant information about Sivaprasad Valluru. He is an instructor with 20 years of experience in IT and has worked with notable companies like Motorola, Alcatel Lucent, and TechMahindra. Currently, he delivers corporate training and has contributed to the Spring framework. He is also certified as an instructor from Mulesoft and Pivotal.\\n\\nI will compile this information into a succinct summary.\\n\\nFinal Answer: Sivaprasad Valluru is an instructor with 20 years of experience in IT, having worked with companies like Motorola, Alcatel Lucent, and TechMahindra. He currently delivers corporate training and has contributed to the Spring framework. He is certified from Mulesoft and Pivotal.'\n",
      "{'output': 'Sivaprasad Valluru is an instructor with 20 years of experience in IT, having worked with companies like Motorola, Alcatel Lucent, and TechMahindra. He currently delivers corporate training and has contributed to the Spring framework. He is certified from Mulesoft and Pivotal.'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "agent_step = \"\"\n",
    "\n",
    "while not isinstance(agent_step, AgentFinish):\n",
    "    agent_step: Union[AgentAction, AgentFinish] = agent.invoke({\n",
    "        \"input\": \"tell me about Sivaprasad valluru\",\n",
    "        \"intermediate_steps\": intermediate_steps\n",
    "    })\n",
    "    \n",
    "    print(f\"Agent Step = {agent_step}\")\n",
    "    if(isinstance(agent_step, AgentAction)):\n",
    "        tool_name = agent_step.tool\n",
    "        tool_to_use = find_tool_by_name(tools, tool_name)\n",
    "        tool_input = agent_step.tool_input\n",
    "        inputs = tool_input.split(\",\")\n",
    "        if(len(inputs) == 1):\n",
    "            inputs = inputs[0]\n",
    "        \n",
    "        print(f\"Tool Selected = {tool_to_use}\")\n",
    "        print(f\"Tool Inputs = {inputs}\")\n",
    "        observation = tool_to_use.invoke(inputs)\n",
    "        print(f\"Observation = {observation}\")\n",
    "        \n",
    "        \n",
    "        intermediate_steps.append((agent_step, str(observation)))\n",
    "        print(\"Intermediate Step = {format_log_to_str(intermediate_steps)}\")\n",
    "    \n",
    "    if(isinstance(agent_step, AgentFinish)):\n",
    "        print(agent_step.return_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a69f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Step = tool='multiply' tool_input='3, 4  \\n\\n' log=\"To solve the expression \\\\(2 + 3 \\\\times 4\\\\), I need to perform the multiplication first, as per the order of operations (PEMDAS/BODMAS).\\n\\nLet's calculate the multiplication part first.\\n\\nAction: multiply  \\nAction Input: 3, 4  \\n\\n\"\n",
      "Tool Selected = name='multiply' description='Multiplies a and b' args_schema=<class 'langchain_core.utils.pydantic.multiply'> func=<function multiply at 0x0000021BFCC9DEE0>\n",
      "Tool Inputs = 3, 4\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='3, 4', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': '3, 4'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTool Selected = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool_to_use\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTool Inputs = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m observation = \u001b[43mtool_to_use\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObservation = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m intermediate_steps.append((agent_step, \u001b[38;5;28mstr\u001b[39m(observation)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:604\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    601\u001b[39m     **kwargs: Any,\n\u001b[32m    602\u001b[39m ) -> Any:\n\u001b[32m    603\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:888\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    887\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:850\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    848\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    854\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:765\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    758\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    759\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    762\u001b[39m ):\n\u001b[32m    763\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    767\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:646\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    644\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    648\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='3, 4', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': '3, 4'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "agent_step = \"\"\n",
    "\n",
    "while not isinstance(agent_step, AgentFinish):\n",
    "    agent_step: Union[AgentAction, AgentFinish] = agent.invoke({\n",
    "        \"input\": \"What is 2 + 3 multiplied by 4\",\n",
    "        \"intermediate_steps\": intermediate_steps\n",
    "    })\n",
    "    \n",
    "    print(f\"Agent Step = {agent_step}\")\n",
    "    if(isinstance(agent_step, AgentAction)):\n",
    "        tool_name = agent_step.tool\n",
    "        tool_to_use = find_tool_by_name(tools, tool_name)\n",
    "        tool_input = agent_step.tool_input\n",
    "        inputs = tool_input.split(\",\")\n",
    "        if(len(inputs) == 1):\n",
    "            inputs = inputs[0]\n",
    "        else:\n",
    "            inputs = tool_input.replace(\"\\n\", \"\").replace(\"'\", \"\").strip()\n",
    "        \n",
    "        print(f\"Tool Selected = {tool_to_use}\")\n",
    "        print(f\"Tool Inputs = {inputs}\")\n",
    "        observation = tool_to_use.invoke(inputs)\n",
    "        print(f\"Observation = {observation}\")\n",
    "        \n",
    "        \n",
    "        intermediate_steps.append((agent_step, str(observation)))\n",
    "        print(\"Intermediate Step = {intermediate_steps}\")\n",
    "    \n",
    "    if(isinstance(agent_step, AgentFinish)):\n",
    "        print(agent_step.return_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8068f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd250a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"hwchase17/react\", include_model=True)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39094278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find current information about Leela Prasad Jagu, as I don't have any knowledge about this individual. \n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Leela Prasad Jagu\"\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Leela Prasad - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Leela_Prasad', 'content': 'Leela Prasad is an Indian historian based in the United States. A scholar of Indian history and the anthropology of ethics, she is a 2023 Guggenheim Fellow and is St. Purandar Das Distinguished Professor of Religious Studies at Brown University.(\\n\\nBiography\\n\\n[edit] [...] As an academic, Prasad specialises in the anthropology of ethics, early Indic philology, history of India, and oral history.( She curated a Historical Society of Pennsylvania exhibition on the history of the South Asian Americans in the Delaware Valley, and she subsequently edited a tie-in 1999 volume _Live Like the Banyan Tree_.( In 2006, she worked on two books: as co-editor of _Gender and Story in South India_ and as author of _Poetics of Conduct\")_,( for which she won the 2007 American [...] Categories: \\n   Living people\\n   Indian women historians\\n   21st-century Indian historians\\n   20th-century Indian historians\\n   Historians of India\\n   Historians of religion\\n   Indian film directors\\n   Indian women film directors\\n   Indian expatriate academics in the United States\\n   Presidents of the American Academy of Religion\\n   Osmania University alumni\\n   University of Hyderabad alumni\\n   Kansas State University alumni\\n   University of Pennsylvania alumni\\n   Duke University faculty', 'score': 0.7746691}, {'title': 'Leela Prasad - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Leela_Prasad#:~:text=Leela Prasad is an Indian,Religious Studies at Brown University.', 'content': 'Leela Prasad is an Indian historian based in the United States. A scholar of Indian history and the anthropology of ethics, she is a 2023 Guggenheim Fellow and is St. Purandar Das Distinguished Professor of Religious Studies at Brown University.\\n\\n## Biography [...] As an academic, Prasad specialises in the anthropology of ethics, early Indic philology, history of India, and oral history. She curated a Historical Society of Pennsylvania exhibition on the history of the South Asian Americans in the Delaware Valley, and she subsequently edited a tie-in 1999 volume Live Like the Banyan Tree. In 2006, she worked on two books: as co-editor of Gender and Story in South India and as author of Poetics of Conduct\"), for which she won the 2007 American Academy of [...] Assistant Professor from 2002 to 2003. She became an associate professor in 2007, and In 2020, she became a full professor. She also held an associate professorship at Duke\\'s Department of Asian and Middle Eastern Studies from 2013 to 2015. In 2024, she moved from Duke to the Brown University Department of Religious Studies.', 'score': 0.71377134}, {'title': 'Leela Prasad – AAR - American Academy of Religion', 'url': 'https://aarweb.org/person/leela-prasad/', 'content': 'Leela Prasad serves as the AAR’s President from November 2024 to November 2025. She is the St. Purandar Das Distinguished Professor of Religious Studies at Brown University. [...] Leela Prasad (Ph.D. Folklore & Folklife, University of Pennsylvania) joined Brown’s Department of Religious Studies in 2024 after 25 years at Duke University. She is interested in the anthropology of ethics, human rights and social justice, gender, diasporic life, storytelling and performance, colonialism & decoloniality, prison and post-prison life, and Gandhi. She enjoys putting early Indic literary and religious thought into conversation with contemporary practices of everyday life. Her [...] Apart from university teaching, Leela teaches graduate seminars on Gandhi in US prisons. She is also documenting the life-stories of Gandhi-inspired individuals in India who read Gandhi while serving prison terms. With her collaborator, Baba Prasad, she is co-directing a film called Let Us Seeon the lifelong resonance Gandhi on a schoolteacher who met him in 1944 when India was on the brink of freedom from colonial rule.', 'score': 0.5818027}, {'title': 'Leela Prasad | Saxena Center for Contemporary South Asia', 'url': 'https://saxena.watson.brown.edu/people/leela-prasad', 'content': \"She has received grants from the American Academy of Religion, the National Endowment for the Humanities, and the American Philosophical Society. She held Fulbright-Nehru senior fellowships in 2020 and 2022, and a Guggenheim Fellowship in 2023-2024. Leela is President-Elect of the American Academy of Religion and will become its President in November 2024.\\n\\n## Quick Navigation\\n\\n## Footer Navigation\\n\\n© Brown University\\n\\n## Mobile Site Navigation\\n\\n## Mobile Site Navigation\\n\\n### Leela Prasad [...] Leela Prasad (Ph.D. Folklore & Folklife, University of Pennsylvania) joined Brown's Department of Religious Studies in 2024 after 25 years at Duke University. She is interested in the anthropology of ethics, human rights and social justice, gender, diasporic life, storytelling and performance, colonialism & decoloniality, prison and post-prison life, and Gandhi. She enjoys putting early Indic literary and religious thought into conversation with contemporary practices of everyday life. Her [...] Apart from university teaching, Leela teaches graduate seminars on Gandhi in US prisons. She is also documenting the life-stories of Gandhi-inspired individuals in India who read Gandhi while serving prison terms. With her collaborator, Baba Prasad, she is co-directing a film called Let Us Seeon the lifelong resonance Gandhi on a schoolteacher who met him in 1944 when India was on the brink of freedom from colonial rule.\", 'score': 0.5492786}, {'title': 'About Leela Prasad | The Loom & The Wheel', 'url': 'http://www.duke.edu/~leela/dukeengage/about_leela_prasad_2.html', 'content': 'LEELA PRASAD directs the DukeEngage-Hyderabad program. She is Associate Professor of Ethics and Indian Religions in the Department of Religion at Duke University. She received her PhD in Folklore and Folklife from the University of Pennsylvania in 1998. Her interests are in ethics and its ‘lived,’ expressive dimensions, particularly in Hindu contexts. She also works in the areas of colonial and postcolonial anthropology of India, folklore, narrative, gender, and the South Asian American', 'score': 0.54535896}]\u001b[0m\u001b[32;1m\u001b[1;3mLeela Prasad Jagu, also known as Leela Prasad, is an Indian historian currently based in the United States. She is recognized for her contributions to the fields of Indian history and the anthropology of ethics. As of 2023, she holds the position of St. Purandar Das Distinguished Professor of Religious Studies at Brown University and has been awarded a Guggenheim Fellowship.\n",
      "\n",
      "During her academic career, she has specialized in various areas including the anthropology of ethics, early Indic philology, oral history, and has worked on the history of South Asian Americans. Notably, she has curated exhibitions and edited significant publications that reflect her scholarly interests.\n",
      "\n",
      "Prasad has previously taught at Duke University for 25 years before joining Brown University in 2024. Beyond academia, she is involved in documenting the lives of Gandhi-inspired individuals and co-directing a film about the resonance of Gandhi's impact on everyday life.\n",
      "\n",
      "Furthermore, she is expected to serve as the President of the American Academy of Religion from November 2024 to November 2025.\n",
      "\n",
      "Final Answer: Leela Prasad is an Indian historian and scholar specializing in Indian history and the anthropology of ethics, currently a professor at Brown University and a 2023 Guggenheim Fellow.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # stop_sequences= [\"Observation\", \"\\nObservation\"]\n",
    ")\n",
    "\n",
    "\n",
    "tools = [tavily_search_tool, add, subtract, multiply]\n",
    "agent = create_react_agent(llm=llm, \n",
    "                           tools=tools, \n",
    "                           prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "result = agent_executor.invoke({\"input\": \"Tell me about Leela Prasad Jagu\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a95763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "class ArthimeticArgs(BaseModel):\n",
    "    a: int\n",
    "    b: int\n",
    "    \n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b\"\"\"\n",
    "    return int(a) + int(b)\n",
    "\n",
    "def subtract(a: int, b: int) ->int:\n",
    "    \"\"\"Subtracts b from a\"\"\"\n",
    "    return int(a) - int(b)\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b\"\"\"\n",
    "    print(\"Args:: \", a, b)\n",
    "    return int(a) * int(b)\n",
    "\n",
    "\n",
    "multiply_tool = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    args_schema=ArthimeticArgs,\n",
    "    description=\"Multiplies 2 numbers\"\n",
    ")\n",
    "\n",
    "add_tool = StructuredTool.from_function(\n",
    "    func=add,\n",
    "    args_schema=ArthimeticArgs,\n",
    "    description=\"Adds 2 numbers\"\n",
    ")\n",
    "\n",
    "subtract_tool = StructuredTool.from_function(\n",
    "    func=subtract,\n",
    "    args_schema=ArthimeticArgs,\n",
    "    description=\"Subtracts 2 numbers\"\n",
    ")\n",
    "\n",
    "tools = [tavily_search_tool, add_tool, subtract_tool, multiply_tool]\n",
    "\n",
    "from langsmith import Client\n",
    "from langchain.prompts import PromptTemplate\n",
    "client = Client()\n",
    "base_prompt = client.pull_prompt(\"hwchase17/react\", include_model=True)\n",
    "\n",
    "custom_instructions = \"\"\"\n",
    "When calling tools, ALWAYS pass arguments as strict JSON not as a string. \n",
    "- Use integers, not strings.\n",
    "- Example: pass arguments like 3, 4 \n",
    "- NEVER combine numbers into one string like \"3, 4\".\n",
    "- NEVER use tuples like (3, 4).\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=base_prompt.input_variables,\n",
    "    template=base_prompt.template + \"\\n\\n\" + custom_instructions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b10d5a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is 2 + 3 multiplied by 4  \n",
      "Thought: I need to follow the order of operations (PEMDAS/BODMAS). First, I need to calculate multiplication before addition. So, I will multiply 3 by 4 and then add 2 to the result.  \n",
      "Action: multiply  \n",
      "Action Input: 3, 4  \u001b[0m"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for ArthimeticArgs\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='3, 4', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': '3, 4'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n\u001b[32m      3\u001b[39m agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 2 + 3 multiplied by 4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:888\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    887\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:850\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    848\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    854\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:765\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    758\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    759\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    762\u001b[39m ):\n\u001b[32m    763\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    767\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:646\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    644\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    648\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Leela\\genai_workspace\\.venv\\Lib\\site-packages\\pydantic\\main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for ArthimeticArgs\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='3, 4', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': '3, 4'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"What is 2 + 3 multiplied by 4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67121f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b677d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Elon Musk'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Elon Musk | SpaceX, Tesla, Twitter, X, Trump, DOGE, & Facts', 'url': 'https://www.britannica.com/money/Elon-Musk', 'content': 'Elon Musk (born June 28, 1971, Pretoria, South Africa) is a South African–born American entrepreneur who cofounded the electronic payment firm PayPal and formed SpaceX, maker of launch vehicles and spacecraft. He was also one of the first significant investors in, as well as chief executive officer of, the electric car manufacturer Tesla. In addition, Musk acquired Twitter (later X) in 2022. Musk led the Department of Government Efficiency (DOGE) in U.S. President Donald Trump’s second [...] Elon Musk cofounded the electronic payment firm PayPal, and in 2002 he founded SpaceX, a company that makes rockets and spacecraft. He was a major early funder of Tesla, which makes electric cars and batteries, and became its chief executive officer in 2008. He cofounded Neuralink, a neurotechnology company, in 2016. Musk purchased the social media service Twitter in 2022 and renamed it X in 2023. [...] Elon Musk went to Queen’s University in Kingston, Ontario, Canada, and then transferred to the University of Pennsylvania in Philadelphia, where he received bachelor’s degrees in physics and economics in 1997. He began graduate school in physics at Stanford University but left after several days to focus on being an entrepreneur. \\n\\n### What are Elon Musk’s top accomplishments?', 'score': 0.9381752}, {'title': 'Elon Musk - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Elon_Musk', 'content': 'Elon Reeve Musk (/ˈ iː l ɒ n/_EE-lon_; born June 28, 1971) is an international businessman and entrepreneur known for his leadership of Tesla, SpaceX, X (formerly Twitter) \"X (formerly Twitter)\"), and the Department of Government Efficiency (DOGE). Musk has been the wealthiest person in the world since 2021; as of May 2025,( estimates his net worth to be US$424.7 billion. [...] Elon Reeve Musk was born on June 28, 1971, in Pretoria, South Africa\\'s administrative capital.( He is of British and Pennsylvania Dutch ancestry.( His mother, Maye (néeHaldeman), is a model and dietitian born in Saskatchewan, Canada, and raised in South Africa.( Musk therefore holds both South African and Canadian citizenship from birth.( His father, Errol Musk, is a South African electromechanical engineer, pilot, sailor, consultant, emerald dealer, and property developer, who partly owned a [...] Born to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada; he had obtained Canadian citizenship at birth through his Canadian-born mother. He received bachelor\\'s degrees in 1997 from the University of Pennsylvania in Philadelphia, United States, before moving to California to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com \"X.com (bank)\"), an online payment company that later merged to form', 'score': 0.926683}, {'title': 'Elon Musk: Biography, Entrepreneur, SpaceX and Tesla Founder', 'url': 'https://www.biography.com/business-leaders/elon-musk', 'content': 'Musk is the cofounder, CEO, and product architect at Tesla Motors, a company formed in 2003 that is dedicated to producing affordable, mass-market electric cars as well as battery products and solar roofs. Musk oversees all product development, engineering, and design of the Texas-based company’s products. [...] Musk is the richest person in the world, a title he has held at various points since early 2021. He regularly swaps spots with Amazon founder Jeff Bezos and French businessman Bernard Arnault, who is the founder and CEO of luxury goods conglomerate LVMH. [...] Following Trump’s announcement in June 2017 that he was withdrawing the United States from the Paris climate accord, Musk stepped down from his advisory roles.\\n\\nGetty Images\\n\\nElon Musk, who had served as an advisor in President Donald Trump’s first administration, took an active role in the Republican candidate’s 2024 reelection campaign.', 'score': 0.82795376}, {'title': \"Elon Musk's Net Worth Just Hit A New Record—Here's ...\", 'url': 'https://www.investopedia.com/elon-musk-net-worth-record-usd500-billion-11823006', 'content': \"Musk is also the cofounder and CEO of SpaceX, a rocket manufacturing company that counts NASA as a client and helps resupply the International Space Station.7\\n\\nSpaceX became the most valuable startup in the world when it considered raising funds at a $400 billion valuation in July 2025, according to _Bloomberg._ 8\\n\\nMusk owns 42% of SpaceX, which has launched over 400 rockets since it was founded in 2002, and has more than 4 million subscribers for its Starlink internet service.9 10 11 [...] Tesla CEO Elon Musk, the richest person in the world, saw his net worth surpass $500 billion in October 2025. He is the first person to hit that milestone.\\n   Musk is Tesla's largest shareholder, with 19.7% of the company's equity as of August, 2025. Rising Tesla share prices fueled Musk's record net worth.\\n   A new proposed pay package, that could grant Musk additional Tesla shares, could push his net worth over $1 trillion. [...] The world's richest man just got richer. Elon Musk became the first person with a net worth of $500 billion in October 2025, according to _Forbes_.1\\n\\nRising Tesla shares fueled this jump in Musk's fortune. The company's stock was up nearly 17% year-to-date as of Oct. 2, 2025.\", 'score': 0.7043437}, {'title': 'Elon Musk - BBC News', 'url': 'https://www.bbc.com/news/topics/c302m85q53mt', 'content': \"21 hrs ago Image 2: Tech multi-billionaire Elon Musk speaking at the Conservative Political Action Conference (CPAC) in February 2025. He is dressed all in black, including a Make America Great Again baseball cap, coat, t-shirt and sunglasses. The background is bright blue with a large white letter C over Musk's right shoulder. Musk becomes world's first half-trillionaire -------------------------------------------- The rise has been driven by a sharp increase in the value of his electric car [...] 18 Sep 2025 Image 8: Elon Musk stands in the oval office in a black suit jacket, a black tshirt and a black cap with the letters DOGE stitched in. His arms are folded and he is looking downwards. In the background the flag with the President's standard can be seen to the right, it is out of focus. Musk's fellowship of Royal Society in doubt after rally address --------------------------------------------------------------- The world's most prestigious scientific body raised concerns about the\", 'score': 0.650934}]\u001b[0m\u001b[32;1m\u001b[1;3mElon Musk is a prominent entrepreneur and businessman, known for his roles in several high-profile companies. Born on June 28, 1971, in Pretoria, South Africa, Musk co-founded the electronic payment firm PayPal and later founded SpaceX in 2002, which specializes in aerospace manufacturing and spacecraft launch. He is also the CEO and product architect of Tesla, an electric car manufacturer that he joined as a major early investor and later assumed leadership in 2008.\n",
      "\n",
      "Musk has played a key role in the development of various innovative technologies, including electric vehicles, solar energy, and space travel. He also founded Neuralink, a neurotechnology company, and acquired Twitter, renaming it X in 2023. His educational background includes degrees in physics and economics from the University of Pennsylvania.\n",
      "\n",
      "Musk has consistently been among the wealthiest individuals globally, often trading places with other billionaires. As of 2025, his net worth is estimated to have surpassed $500 billion, making him the first person to reach such a financial milestone. He has also been involved in political discussions and initiatives, including serving as an advisor in former President Donald Trump's administration.\n",
      "\n",
      "For more detailed insights, you can refer to the following articles:\n",
      "- [Britannica - Elon Musk](https://www.britannica.com/money/Elon-Musk)\n",
      "- [Wikipedia - Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk)\n",
      "- [Biography - Elon Musk](https://www.biography.com/business-leaders/elon-musk)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI.\n",
    "                You should not use tools parallely\n",
    "                You should not make your own conclusions even if it is easy, instead use appropriate tools\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=5)\n",
    "result = agent_executor.invoke({\"input\": \"Tell me about Elon Musk\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dcd78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74822e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
