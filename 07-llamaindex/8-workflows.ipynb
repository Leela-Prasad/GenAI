{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b94b8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-utils-workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2512c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent\n",
    "\n",
    "class MyWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def my_step(self, event: StartEvent) -> StopEvent:\n",
    "        return StopEvent(result=\"Hello World!\")\n",
    "    \n",
    "\n",
    "workflow = MyWorkflow(timeout=10, verbose=True)\n",
    "\n",
    "result = await workflow.run()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3f49c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(MyWorkflow, filename=\"basic_workflow.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c84a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "    \n",
    "class SecondEvent(Event):\n",
    "    second_output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554293f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start the workflow\n",
      "First step complete\n",
      "Second step complete\n",
      "Workflow complete\n",
      "basic_workflow.html\n"
     ]
    }
   ],
   "source": [
    "class MyWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def step_one(self, event: StartEvent) -> FirstEvent:\n",
    "        print(event.first_input)\n",
    "        return FirstEvent(first_output=\"First step complete\")\n",
    "    \n",
    "    @step\n",
    "    async def step_two(self, event: FirstEvent) -> SecondEvent:\n",
    "        print(event.first_output)\n",
    "        return SecondEvent(second_output=\"Second step complete\")\n",
    "    \n",
    "    @step\n",
    "    async def step_three(self, event: SecondEvent) -> StopEvent:\n",
    "        print(event.second_output)\n",
    "        return StopEvent(result=\"Workflow complete\")\n",
    "    \n",
    "\n",
    "w = MyWorkflow(timeout=10, verbose=True)\n",
    "result = await w.run(first_input=\"start the workflow\")\n",
    "print(result)\n",
    "\n",
    "draw_all_possible_flows(MyWorkflow, filename=\"basic_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767f902",
   "metadata": {},
   "source": [
    "Branch Workflow (IF ELSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df26da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchA1Event(Event):\n",
    "    payload: str\n",
    "    \n",
    "class BranchA2Event(Event):\n",
    "    payload: str\n",
    "    \n",
    "class BranchB1Event(Event):\n",
    "    payload: str\n",
    "    \n",
    "class BranchB2Event(Event):\n",
    "    payload: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05edecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_workflow.html\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class BranchWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def start(self, event: StartEvent) -> BranchA1Event | BranchB1Event:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"Go to Branch A\")\n",
    "            return BranchA1Event(payload=\"Branch A\")\n",
    "        else:\n",
    "            print(\"Go to Branch B\")\n",
    "            return BranchB1Event(payload=\"Branch B\")\n",
    "        \n",
    "    @step\n",
    "    async def step_a1(self, event: BranchA1Event) -> BranchA2Event:\n",
    "        print(event.payload)\n",
    "        return BranchA2Event(payload=event.payload)\n",
    "    \n",
    "    @step\n",
    "    async def step_a2(self, event: BranchA2Event) -> StopEvent:\n",
    "        print(event.payload)\n",
    "        return StopEvent(payload=\"Branch A Complete\")\n",
    "    \n",
    "    @step\n",
    "    async def step_b1(self, event: BranchB1Event) -> BranchB2Event:\n",
    "        print(event.payload)\n",
    "        return BranchB2Event(payload=event.payload)\n",
    "    \n",
    "    @step\n",
    "    async def step_b2(self, event: BranchB2Event) -> StopEvent:\n",
    "        print(event.payload)\n",
    "        return StopEvent(payload=\"Branch B Complete\")\n",
    "    \n",
    "draw_all_possible_flows(BranchWorkflow, filename=\"branch_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc63c6",
   "metadata": {},
   "source": [
    "Loop Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52db7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "class TextEvent(Event):\n",
    "    text: str\n",
    "    iteration: int = 0\n",
    "    \n",
    "class EvaluationEvent(Event):\n",
    "    text: str\n",
    "    feedback: str\n",
    "    score: float\n",
    "    iteration: int\n",
    "    \n",
    "class FinalTextEvent(Event):\n",
    "    text: str\n",
    "    iterations_required: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c039936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text_refinement_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, step\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "class TextRefinementWorkflow(Workflow):\n",
    "    \n",
    "    def __init__(self, timeout=60, verbose=False, max_iterations=5):\n",
    "        super().__init__(timeout=timeout, verbose=verbose)\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "    \n",
    "    @step\n",
    "    async def initialize_text(self, event: StartEvent) -> TextEvent:\n",
    "        initial_text = event.initial_text\n",
    "        print(f\"Initial Text Received (Iteration 0): {initial_text}\")\n",
    "        return TextEvent(text=initial_text, iteration=0)\n",
    "    \n",
    "    @step\n",
    "    async def grade_text(self, event: TextEvent) -> EvaluationEvent | FinalTextEvent:\n",
    "        if event.iteration >= self.max_iterations:\n",
    "            print(f\"Reached Maximum Iterations (Iteration {self.max_iterations})\")\n",
    "            return FinalTextEvent(text=event.text, iterations_required=event.iteration)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following text for clarity, coherence and conciseness\n",
    "        \n",
    "        Text: \n",
    "        {event.text}\n",
    "        \n",
    "        Provide:\n",
    "        1. A score from 0-10(where 0 is least score and 10 is highest score)\n",
    "        2. Specific feedback on how to improve\n",
    "        \n",
    "        Format your response exactly as:\n",
    "        SCORE: [number]\n",
    "        FEEDBACK: [your feedback]\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        result = response.text.strip()\n",
    "        \n",
    "        score_line = [line for line in result.split(\"\\n\") if line.startswith(\"SCORE:\")][0]\n",
    "        score = float(score_line.split(\"SCORE:\")[1].strip())\n",
    "        \n",
    "        feedback_line = [line for line in result.split(\"\\n\") if line.startswith(\"FEEDBACK:\")][0]\n",
    "        feedback = feedback_line.split(\"FEEDBACK:\")[1].strip()\n",
    "        \n",
    "        print(f\"Evaluation Iteration (Iteration {event.iteration})\")\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Feedback: {feedback}\")\n",
    "        \n",
    "        if score > 8:\n",
    "            print(f\"Quality threshold met after {event.iteration} iterations!\")\n",
    "            return FinalTextEvent(text=feedback, iterations_required=event.iteration)\n",
    "        \n",
    "        return EvaluationEvent(text=event.text, feedback=feedback,\n",
    "                               score=score, iteration=event.iteration)\n",
    "        \n",
    "    \n",
    "    @step\n",
    "    async def refine_text(self, event: EvaluationEvent) -> TextEvent:\n",
    "        prompt = f\"\"\"\n",
    "        Please improve the following text based on this feedback.\n",
    "        \n",
    "        Original Text:\n",
    "        {event.text}\n",
    "        \n",
    "        Feedback:\n",
    "        {event.feedback}\n",
    "        \n",
    "        Current Score: {event.score}\n",
    "        \n",
    "        Provide an improved version that addresses all the feeback points.\n",
    "        Only return the improved text with no additional commentary\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        result = response.text.strip()\n",
    "        iteration = event.iteration + 1\n",
    "    \n",
    "        print(f\"Refined Text (Iteration {iteration}: {result})\")    \n",
    "        return TextEvent(text=result, iteration=iteration)\n",
    "    \n",
    "    \n",
    "    @step\n",
    "    async def finalize_text(self, event: FinalTextEvent) -> StopEvent:\n",
    "        result = {\n",
    "            \"text\": event.text,\n",
    "            \"iterations\": event.iterations_required\n",
    "        }\n",
    "        \n",
    "        return StopEvent(result=result)\n",
    "    \n",
    "    \n",
    "\n",
    "draw_all_possible_flows(TextRefinementWorkflow, filename=\"Text_refinement_workflow.html\")        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c82c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Text Received (Iteration 0): \n",
      "    Machine Learning is a process where computer systems can learn from data without being explicitly programmed.\n",
      "    It uses algorithms to identify patterns in data and make predictions. Its used in many applications today.\n",
      "\n",
      "Evaluation Iteration (Iteration 0)\n",
      "Score: 7.0\n",
      "Feedback: The text is generally clear and conveys the main idea of machine learning effectively. However, it could be improved in terms of coherence and conciseness. Here are some suggestions:\n",
      "Refined Text (Iteration 1: Machine learning is a process that enables computer systems to learn from data without explicit programming. By utilizing algorithms, it identifies patterns and makes predictions. Today, it is applied across various fields and industries.)\n",
      "Evaluation Iteration (Iteration 1)\n",
      "Score: 8.0\n",
      "Feedback: The text is clear and coherent, effectively conveying the concept of machine learning and its applications. However, it could be more concise by eliminating some redundancy. For example, the phrase \"learn from data without explicit programming\" could be simplified to \"learn from data without programming.\" Additionally, providing specific examples of fields and industries where machine learning is applied would enhance clarity and engagement.\n",
      "Refined Text (Iteration 2: Machine learning is a process that enables computer systems to learn from data without programming. By utilizing algorithms, it identifies patterns and makes predictions. Today, it is applied in various fields, including healthcare, finance, and marketing.)\n",
      "Evaluation Iteration (Iteration 2)\n",
      "Score: 8.0\n",
      "Feedback: The text is generally clear and coherent, effectively conveying the concept of machine learning and its applications. However, it could be improved by providing a brief example of how machine learning is used in one of the mentioned fields, which would enhance understanding. Additionally, the phrase \"learn from data without programming\" could be rephrased for clarity, as it may imply that no programming is involved at all, which is misleading. A more precise wording could be \"learn from data without explicit programming for each task.\" Overall, the text is concise but could benefit from a bit more detail to enrich the reader's understanding.\n",
      "Refined Text (Iteration 3: Machine learning is a process that enables computer systems to learn from data without explicit programming for each task. By utilizing algorithms, it identifies patterns and makes predictions. For example, in healthcare, machine learning algorithms can analyze medical images to detect diseases such as cancer at an early stage. Today, machine learning is applied in various fields, including healthcare, finance, and marketing.)\n",
      "Evaluation Iteration (Iteration 3)\n",
      "Score: 8.0\n",
      "Feedback: The text is generally clear and coherent, effectively explaining the concept of machine learning and providing a relevant example. However, it could be more concise by eliminating some redundancy. For instance, the phrase \"without explicit programming for each task\" could be simplified to \"without explicit programming.\" Additionally, the sentence \"Today, machine learning is applied in various fields, including healthcare, finance, and marketing\" could be shortened to \"Machine learning is now applied in various fields, such as healthcare, finance, and marketing.\" Overall, tightening the language would enhance clarity and conciseness.\n",
      "Refined Text (Iteration 4: Machine learning is a process that enables computer systems to learn from data without explicit programming. By utilizing algorithms, it identifies patterns and makes predictions. For example, in healthcare, machine learning algorithms can analyze medical images to detect diseases like cancer at an early stage. Machine learning is now applied in various fields, such as healthcare, finance, and marketing.)\n",
      "Evaluation Iteration (Iteration 4)\n",
      "Score: 8.0\n",
      "Feedback: The text is generally clear and coherent, effectively explaining the concept of machine learning and providing a relevant example. However, it could be more concise by eliminating redundancy. For instance, the phrase \"machine learning algorithms\" could be simplified to \"machine learning\" since the context is already established. Additionally, the last sentence could be rephrased to avoid repetition of \"machine learning\" and instead say, \"It is now applied in various fields, including healthcare, finance, and marketing.\" This would enhance the overall flow and brevity of the text.\n",
      "Refined Text (Iteration 5: Machine learning is a process that enables computer systems to learn from data without explicit programming. By utilizing algorithms, it identifies patterns and makes predictions. For example, in healthcare, machine learning can analyze medical images to detect diseases like cancer at an early stage. It is now applied in various fields, including finance and marketing.)\n",
      "Reached Maximum Iterations (Iteration 5)\n"
     ]
    }
   ],
   "source": [
    "workflow = TextRefinementWorkflow()\n",
    "\n",
    "initial_text = \"\"\"\n",
    "    Machine Learning is a process where computer systems can learn from data without being explicitly programmed.\n",
    "    It uses algorithms to identify patterns in data and make predictions. Its used in many applications today.\n",
    "\"\"\"\n",
    "\n",
    "result = await workflow.run(initial_text=initial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48291b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Machine learning is a process that enables computer systems to learn from data without explicit programming. By utilizing algorithms, it identifies patterns and makes predictions. For example, in healthcare, machine learning can analyze medical images to detect diseases like cancer at an early stage. It is now applied in various fields, including finance and marketing.',\n",
       " 'iterations': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80e066",
   "metadata": {},
   "source": [
    "Maintaining Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399a627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DB Config\n",
      "Querying DB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'jdbc://mock-url'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "class SetupEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "\n",
    "class StatefulWorkFlow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def init(self, ctx: Context, event: StartEvent) -> SetupEvent | QueryEvent:\n",
    "        db_config = await ctx.store.get(\"database_config\", default=None)\n",
    "        if db_config is None:\n",
    "            print(\"Load DB Config\")\n",
    "            return SetupEvent(query=event.query)\n",
    "        \n",
    "        return QueryEvent(query=event.query)\n",
    "    \n",
    "    \n",
    "    @step\n",
    "    async def setup(self, ctx: Context, event:SetupEvent) ->StartEvent:\n",
    "        await ctx.store.set(\"database_config\", {\"url\": \"jdbc://mock-url\"})\n",
    "        return StartEvent(query=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def query(self, ctx: Context, event: QueryEvent) -> StopEvent:\n",
    "        print(\"Querying DB\")\n",
    "        return StopEvent(result = await ctx.store.get(\"database_config\"))\n",
    "\n",
    "\n",
    "workflow = StatefulWorkFlow()\n",
    "result = await workflow.run(query=\"Load Customer Data\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e88a3",
   "metadata": {},
   "source": [
    "Using Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "class DocumentEvent(Event):\n",
    "    document_text: str\n",
    "    \n",
    "class SummarizedEvent(Event):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e6ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, step, Context\n",
    "import hashlib\n",
    "\n",
    "class DocumentWorkflow(Workflow):\n",
    "    \n",
    "    def __init__(self, timeout=30, verbose=False):\n",
    "        super().__init__(timeout=timeout, verbose=verbose)\n",
    "        \n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.summaries_cache = {}\n",
    "        self.processed_count = 0\n",
    "        \n",
    "    def get_document_hash(self, text):\n",
    "        return hashlib.md5(text.encode()).hexdigest()\n",
    "    \n",
    "    @step\n",
    "    async def start(self, ctx: Context, event: StartEvent) -> DocumentEvent:\n",
    "        document_text = event.text\n",
    "        document_hash = self.get_document_hash(document_text)\n",
    "        \n",
    "        using_cache = document_hash in self.summaries_cache\n",
    "        \n",
    "        await ctx.store.set(\"document_hash\", document_hash)\n",
    "        await ctx.store.set(\"using_cache\", using_cache)\n",
    "        \n",
    "        return DocumentEvent(document_text=document_text)\n",
    "    \n",
    "    @step\n",
    "    async def summarize_document(self, ctx: Context, event: DocumentEvent) -> SummarizedEvent:\n",
    "        using_cache = await ctx.store.get(\"using_cache\")\n",
    "        document_hash = await ctx.store.get(\"document_hash\")\n",
    "        \n",
    "        # print(f\"Cache is {using_cache}\")\n",
    "        \n",
    "        if using_cache:\n",
    "            print(\"Retrieved cache summary\")\n",
    "            summary = self.summaries_cache[document_hash]\n",
    "            return SummarizedEvent(summary=summary)\n",
    "        \n",
    "        print(\"Generating New Summary\")\n",
    "        prompt = f\"Please summarize this text in one paragraph:\\n\\n {event.document_text}\"\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        summary = response.text.strip()\n",
    "        \n",
    "        self.summaries_cache[document_hash] = summary\n",
    "        return SummarizedEvent(summary=summary)\n",
    "    \n",
    "    @step\n",
    "    async def final_step(self, ctx: Context, event: SummarizedEvent) -> StopEvent:\n",
    "        self.processed_count += 1\n",
    "        using_cache = await ctx.store.get(\"using_cache\")\n",
    "        \n",
    "        result = {\n",
    "            \"summary\": event.summary,\n",
    "            \"from_cache\": using_cache,\n",
    "            \"total_processed\": self.processed_count\n",
    "        }\n",
    "        return StopEvent(result = result)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9d4375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating New Summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': 'Machine Learning is a method that enables computer systems to learn from data autonomously, utilizing algorithms to detect patterns and make predictions. This technology is widely applied across various fields today.',\n",
       " 'from_cache': False,\n",
       " 'total_processed': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = DocumentWorkflow()\n",
    "\n",
    "text = \"Machine Learning is a process where computer systems can learn from data without being explicitly programmed.It uses algorithms to identify patterns in data and make predictions. Its used in many applications today.\"\n",
    "result = await workflow.run(text=text)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a10b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved cache summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': 'Machine Learning is a method that enables computer systems to learn from data autonomously, utilizing algorithms to detect patterns and make predictions. This technology is widely applied across various fields today.',\n",
       " 'from_cache': True,\n",
       " 'total_processed': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = await workflow.run(text=text)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0d5f7",
   "metadata": {},
   "source": [
    "### Streaming Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7a3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "    \n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "    response: str\n",
    "    \n",
    "class ProgressEvent(Event):\n",
    "    msg: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dfc2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def step_one(self, ctx: Context, event: StartEvent) -> FirstEvent:\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=\"Event :: Step one is happening\"))\n",
    "        return FirstEvent(first_output=\"First step complete\")\n",
    "    \n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, event: FirstEvent) -> SecondEvent:\n",
    "        llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        generator = await llm.astream_complete(\"Tell me about Elon Musk in 5 sentences\")\n",
    "        \n",
    "        async for token in generator:\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=token.delta))\n",
    "            \n",
    "        return SecondEvent(second_output=\"Second step complete\", response=str(token))\n",
    "    \n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, event: SecondEvent) -> StopEvent:\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=\"Event :: Step three is happening\"))\n",
    "        return StopEvent(result=\"Workflow Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c64301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event :: Step one is happeningElon Musk is a billionaire entrepreneur and CEO known for his role in revolutionizing multiple industries, including electric vehicles, space travel, and renewable energy. He co-founded Zip2 and X.com, which later became PayPal, before founding SpaceX in 2002 with the goal of reducing space transportation costs and enabling the colonization of Mars. Musk is also the CEO and product architect of Tesla, Inc., which has played a significant role in popularizing electric cars and sustainable energy solutions. In addition to these ventures, he has initiated projects like Neuralink, aimed at developing brain-computer interfaces, and The Boring Company, focused on tunnel construction and infrastructure. Musk is known for his ambitious vision for the future, often pushing the boundaries of technology and innovation.Event :: Step three is happeningStreaming completed\n",
      "Workflow Complete\n"
     ]
    }
   ],
   "source": [
    "workflow = MyWorkflow()\n",
    "handler = workflow.run()\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg, sep=\"\", end=\"\")\n",
    "        \n",
    "print(\"Streaming completed\")\n",
    "final_result = await handler\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7bf0ad",
   "metadata": {},
   "source": [
    "### Concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1edd0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class StepThreeEvent(Event):\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65c783",
   "metadata": {},
   "source": [
    "send_event() will trigger other steps in workflow  - internal to workflow\n",
    "write_event_to_stream() will be for streaming logs, llm tokens, progress - external to workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d8b0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "class ConcurrentFlow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def start(self, ctx: Context, event: StartEvent) -> StepTwoEvent:\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 3\"))\n",
    "        \n",
    "    # Here num_workers is the concurrency limit, only 4 will run at same time \n",
    "    # default is unlimited\n",
    "    @step(num_workers=4)\n",
    "    async def step_two(self, ctx: Context, event: StepTwoEvent) -> StepThreeEvent:\n",
    "        print(\"Running Query \", event.query)\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "        return StepThreeEvent(result=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, event: StepThreeEvent) -> StopEvent:\n",
    "        result = ctx.collect_events(event, [StepThreeEvent] * 3)\n",
    "\n",
    "        # If collect_events didn't all 3 StepThreeEvent then it will return None\n",
    "        # so if the result is None we will return None to wait to for all 3 events to receive\n",
    "        \n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        print(result)\n",
    "        return StopEvent(result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3c0b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Query  Query 1\n",
      "Running Query  Query 2\n",
      "Running Query  Query 3\n",
      "[StepThreeEvent(result='Query 2'), StepThreeEvent(result='Query 1'), StepThreeEvent(result='Query 3')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[StepThreeEvent(result='Query 2'),\n",
       " StepThreeEvent(result='Query 1'),\n",
       " StepThreeEvent(result='Query 3')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = ConcurrentFlow()\n",
    "result = await workflow.run()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63c4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event, StartEvent, StopEvent\n",
    "\n",
    "class StepAEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class StepBEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class StepCEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class StepACompleteEvent(Event):\n",
    "    result: str\n",
    "    \n",
    "class StepBCompleteEvent(Event):\n",
    "    result: str\n",
    "    \n",
    "class StepCCompleteEvent(Event):\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e74d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Workflow, Context, step\n",
    "\n",
    "class ConcurrentWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def start(self, ctx: Context, event: StartEvent) -> StepAEvent | StepBEvent | StepCEvent:\n",
    "        ctx.send_event(StepAEvent(query=\"Query1\"))\n",
    "        ctx.send_event(StepBEvent(query=\"Query2\"))\n",
    "        ctx.send_event(StepCEvent(query=\"Query3\"))\n",
    "        \n",
    "    @step\n",
    "    async def step_a(self, ctx: Context, event: StepAEvent) -> StepACompleteEvent:\n",
    "        print(\"Doing something A-ish\")\n",
    "        return StepACompleteEvent(result=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_b(self, ctx: Context, event: StepBEvent) -> StepBCompleteEvent:\n",
    "        print(\"Doing something B-ish\")\n",
    "        return StepBCompleteEvent(result=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_c(self, ctx: Context, event: StepCEvent) -> StepCCompleteEvent:\n",
    "        print(\"Doing something C-ish\")\n",
    "        return StepCCompleteEvent(result=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_three(self, ctx: Context,\n",
    "            event: StepACompleteEvent | StepBCompleteEvent | StepCCompleteEvent) -> StopEvent:\n",
    "        \n",
    "        print(\"Received Event\", event.result)\n",
    "        result = ctx.collect_events(event, [StepACompleteEvent, StepBCompleteEvent, StepCCompleteEvent])\n",
    "        \n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        print(\"Final Result\", result)\n",
    "        return StopEvent(result=\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c365fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing something A-ish\n",
      "Doing something B-ish\n",
      "Doing something C-ish\n",
      "Received Event Query1\n",
      "Received Event Query2\n",
      "Received Event Query3\n",
      "Received Event Query2\n",
      "Received Event Query3\n",
      "Received Event Query3\n",
      "Final Result [StepACompleteEvent(result='Query1'), StepBCompleteEvent(result='Query2'), StepCCompleteEvent(result='Query3')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = ConcurrentWorkflow()\n",
    "await w.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7ba154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "class Step2Event(Event):\n",
    "    query: str\n",
    "    \n",
    "class Step3Event(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09010c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting up\n",
      "Sending an email\n",
      "Finishing up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Initial Query'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MainWorkflow(Workflow):\n",
    "    @step\n",
    "    async def start(self, event: StartEvent) -> Step2Event:\n",
    "        print(\"starting up\")\n",
    "        return Step2Event(query=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_two(self, event: Step2Event) -> Step3Event:\n",
    "        print(\"Sending an email\")\n",
    "        return Step3Event(query=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_three(self, event: Step3Event) -> StopEvent:\n",
    "        print(\"Finishing up\")\n",
    "        return StopEvent(result=event.query)\n",
    "    \n",
    "\n",
    "w = MainWorkflow()\n",
    "result = await w.run(query=\"Initial Query\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd2ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting up\n",
      "Sending an email\n",
      "Sending text message\n",
      "Finishing up\n"
     ]
    }
   ],
   "source": [
    "class Step2BEvent(Event):\n",
    "    query: str\n",
    "    \n",
    "class CustomWorkflow(MainWorkflow):\n",
    "    @step\n",
    "    async def step_two(self, event: Step2Event) -> Step2BEvent:\n",
    "        print(\"Sending an email\")\n",
    "        return Step2BEvent(query=event.query)\n",
    "    \n",
    "    @step\n",
    "    async def step_two_b(self, event: Step2BEvent) -> Step3Event:\n",
    "        print(\"Sending text message\")\n",
    "        return Step3Event(query=event.query)\n",
    "    \n",
    "w= CustomWorkflow()\n",
    "result = await w.run(query=\"Initial Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531d2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llama-index-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
