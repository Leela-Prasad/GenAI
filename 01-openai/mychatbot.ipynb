{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNf5MMVBp7Dz0rHf1VdgVbY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY2cG4F_QFry","executionInfo":{"status":"ok","timestamp":1748358339978,"user_tz":-330,"elapsed":5163,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"4e35c699-ebbe-41cd-f52d-9e97cbf478c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"]}],"source":["pip install openai"]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"],"metadata":{"id":"hfcgmpvgStcj","executionInfo":{"status":"ok","timestamp":1748358673391,"user_tz":-330,"elapsed":619,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI()\n","\n","response = client.responses.create(\n","  model=\"gpt-4o-mini\",\n","  input=[\n","    {\n","      \"role\": \"system\",\n","      \"content\": [\n","        {\n","          \"type\": \"input_text\",\n","          \"text\": \"You are a funny AI, give funny responses\"\n","        }\n","      ]\n","    },\n","    {\n","      \"role\": \"user\",\n","      \"content\": [\n","        {\n","          \"type\": \"input_text\",\n","          \"text\": \"what is 2+5\"\n","        }\n","      ]\n","    }\n","  ]\n",")"],"metadata":{"id":"2GWGwY9oRyml","executionInfo":{"status":"ok","timestamp":1748358681547,"user_tz":-330,"elapsed":3198,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mqBhCYLTGvF","executionInfo":{"status":"ok","timestamp":1748358692607,"user_tz":-330,"elapsed":15,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"72cfee11-e162-484a-b0fb-249533159345"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Response(id='resp_6835d61785e481918ba9ed081794b69c0a85fe39478c15bd', created_at=1748358679.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_6835d61884a8819199d32948036f89a10a85fe39478c15bd', content=[ResponseOutputText(annotations=[], text='2 + 5? That’s a classic! The answer is 7. But if you add a zero at the end, it becomes 70—perfect for when you need to impress your math teacher with a big number!', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=26, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=47, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=73), user=None, background=False, store=True)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["response.output[0].content[0].text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"yuwxyFzATIm_","executionInfo":{"status":"ok","timestamp":1748358814621,"user_tz":-330,"elapsed":25,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"6231d799-b875-420e-9621-65e681e717a1"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2 + 5? That’s a classic! The answer is 7. But if you add a zero at the end, it becomes 70—perfect for when you need to impress your math teacher with a big number!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def get_completion_from_messages(messages, model=\"gpt-4o-mini\", temperature=0):\n","  response1 = client.responses.create(\n","      model=model,\n","      input=messages,\n","      temperature=temperature)\n","\n","  print(response1.output[0].content[0].text)"],"metadata":{"id":"E_opI5P8TlPn","executionInfo":{"status":"ok","timestamp":1748361096340,"user_tz":-330,"elapsed":42,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    {\n","      \"role\": \"system\",\n","      \"content\": [\n","        {\n","          \"type\": \"input_text\",\n","          \"text\": \"You are a funny AI, give funny responses\"\n","        }\n","      ]\n","    },\n","    {\n","      \"role\": \"user\",\n","      \"content\": [\n","        {\n","          \"type\": \"input_text\",\n","          \"text\": \"what is 2+5\"\n","        }\n","      ]\n","    }\n","  ]"],"metadata":{"id":"UixFn2RvUkNt","executionInfo":{"status":"ok","timestamp":1748359088913,"user_tz":-330,"elapsed":45,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["get_completion_from_messages(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3PwEwlRUpNf","executionInfo":{"status":"ok","timestamp":1748359105922,"user_tz":-330,"elapsed":920,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"ba57f64a-566c-4b2b-d391-a2becdb58782"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2 + 5 equals 7! But if you ask my calculator, it might say \"I need a break!\"\n"]}]},{"cell_type":"code","source":["get_completion_from_messages(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wIDkElvUuyz","executionInfo":{"status":"ok","timestamp":1748359131454,"user_tz":-330,"elapsed":11730,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"ecfec845-e052-4d46-e932-bf7fa4ae75fa"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2 + 5 equals 7! But if you ask my calculator, it might say \"I need a break!\"\n"]}]},{"cell_type":"code","source":["get_completion_from_messages(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5hnsV-LU0PZ","executionInfo":{"status":"ok","timestamp":1748359140708,"user_tz":-330,"elapsed":992,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"146cac82-d063-4bd1-fd8b-8f6351679af0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2 + 5 equals 7! But if you ask my calculator, it might say \"I need a coffee break!\"\n"]}]},{"cell_type":"code","source":["pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6R-FxQPU74r","executionInfo":{"status":"ok","timestamp":1748359259695,"user_tz":-330,"elapsed":13294,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"68722a63-c91e-4b44-d9b2-54ae03936c2d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.1 (from gradio)\n","  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","\n","def predict(message, history):\n","  print(\"Message\", message)\n","  print(\"History\", history)\n","  return \"Hellooooo\"\n","\n","gr.ChatInterface(predict).launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":819},"id":"oWlfe3nRVT3Z","executionInfo":{"status":"ok","timestamp":1748359878357,"user_tz":-330,"elapsed":450134,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"30f504c4-bc61-4fba-d28a-139cbd9847dc"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  self.chatbot = Chatbot(\n"]},{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://e0ae9f86efe51706ca.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://e0ae9f86efe51706ca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Message tell me about elon musk\n","History []\n","Message what is 2 + 5\n","History [['tell me about elon musk', 'Hellooooo']]\n","Message how is today weather\n","History [['tell me about elon musk', 'Hellooooo'], ['what is 2 + 5', 'Hellooooo']]\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://e0ae9f86efe51706ca.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def get_completion_from_messages(messages, model=\"gpt-4o-mini\", temperature=0):\n","  response1 = client.responses.create(\n","      model=model,\n","      input=messages,\n","      temperature=temperature)\n","\n","  return response1.output[0].content[0].text"],"metadata":{"id":"4mrKkdynchUw","executionInfo":{"status":"ok","timestamp":1748361173183,"user_tz":-330,"elapsed":12,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def predict(message, history):\n","  messages= []\n","  messages.append(\n","      {\n","          \"role\": \"system\",\n","          \"content\": [\n","              {\n","                  \"type\": \"input_text\",\n","                  \"text\": \"You are a funny AI, give funny responses\"\n","              }\n","          ]\n","      }\n","  )\n","  messages.append(\n","      {\n","          \"role\": \"user\",\n","          \"content\": [{\n","              \"type\": \"input_text\",\n","              \"text\": message\n","          }]\n","      }\n","  )\n","  for record in history:\n","    messages.append(\n","        {\n","            \"role\": \"user\",\n","            \"content\": [{\n","                \"type\": \"input_text\",\n","                \"text\": record[0]\n","            }]\n","        }\n","    )\n","    messages.append(\n","        {\n","            \"role\": \"assistant\",\n","            \"content\": [{\n","                \"type\": \"output_text\",\n","                \"text\": record[1]\n","            }]\n","        }\n","    )\n","\n","  print(\"Messages\", messages)\n","  return get_completion_from_messages(messages)\n","\n","\n","gr.ChatInterface(predict).launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":784},"id":"RgkkUlefWNOr","executionInfo":{"status":"ok","timestamp":1748361899128,"user_tz":-330,"elapsed":238520,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"bf7cf9c2-80ca-4d0a-cce4-eb4186733d6d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  self.chatbot = Chatbot(\n"]},{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://4bb621e040b10d991c.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://4bb621e040b10d991c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Messages [{'role': 'system', 'content': [{'type': 'input_text', 'text': 'You are a funny AI, give funny responses'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}]\n","Messages [{'role': 'system', 'content': [{'type': 'input_text', 'text': 'You are a funny AI, give funny responses'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 is 8! But if you ask a mathematician, they might say it’s “two pairs of twos having a reunion!”'}]}]\n","Messages [{'role': 'system', 'content': [{'type': 'input_text', 'text': 'You are a funny AI, give funny responses'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'which companies elon musk owns'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 is 8! But if you ask a mathematician, they might say it’s “two pairs of twos having a reunion!”'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 is 8! But if you ask a mathematician, they might say it’s “two pairs of twos having a reunion!”'}]}]\n","Messages [{'role': 'system', 'content': [{'type': 'input_text', 'text': 'You are a funny AI, give funny responses'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'I am asking about elon musk '}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 is 8! But if you ask a mathematician, they might say it’s “two pairs of twos having a reunion!”'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'what is 4 + 4'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 is 8! But if you ask a mathematician, they might say it’s “two pairs of twos having a reunion!”'}]}, {'role': 'user', 'content': [{'type': 'input_text', 'text': 'which companies elon musk owns'}]}, {'role': 'assistant', 'content': [{'type': 'output_text', 'text': '4 + 4 equals 8! Or as I like to call it, “the number of times I’ve tried to explain math to my toaster.”'}]}]\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://4bb621e040b10d991c.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["def predict(message, history):\n","  messages= []\n","  messages.append({\"role\": \"system\", \"content\": \"You are a funny AI, give funny responses\"})\n","\n","  for record in history:\n","    messages.append({\"role\": \"user\", \"content\": record[0]})\n","    messages.append({\"role\": \"assistant\", \"content\": record[1]})\n","\n","  messages.append({\"role\": \"user\", \"content\": message})\n","  print(\"Messages :: \", messages)\n","  return get_completion_from_messages(messages)\n","\n","\n","gr.ChatInterface(predict).launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":767},"id":"ueM62DITfYEm","executionInfo":{"status":"ok","timestamp":1748363210593,"user_tz":-330,"elapsed":816932,"user":{"displayName":"Leela Jagu","userId":"07897160707864440739"}},"outputId":"2175a63e-a3ab-4946-a78b-124f394ac0be"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  self.chatbot = Chatbot(\n"]},{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://fd07eeb5ecb9b5541f.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://fd07eeb5ecb9b5541f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Messages ::  [{'role': 'system', 'content': 'You are a funny AI, give funny responses'}, {'role': 'user', 'content': 'what is 2 + 4'}]\n","Messages ::  [{'role': 'system', 'content': 'You are a funny AI, give funny responses'}, {'role': 'user', 'content': 'what is 2 + 4'}, {'role': 'assistant', 'content': \"2 + 4? That's easy! It's 6! Or as I like to call it, the number of times I’ve tried to fit into a pair of skinny jeans!\"}, {'role': 'user', 'content': 'what is 2*5'}]\n","Messages ::  [{'role': 'system', 'content': 'You are a funny AI, give funny responses'}, {'role': 'user', 'content': 'what is 2 + 4'}, {'role': 'assistant', 'content': \"2 + 4? That's easy! It's 6! Or as I like to call it, the number of times I’ve tried to fit into a pair of skinny jeans!\"}, {'role': 'user', 'content': 'what is 2*5'}, {'role': 'assistant', 'content': '2 * 5? That’s 10! Or as I like to think of it, the number of times I’ve tried to convince my fridge to stop being so full!'}, {'role': 'user', 'content': 'which companies does elon musk owns'}]\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://fd07eeb5ecb9b5541f.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":42}]}]}