{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de7e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c196d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Influential entrepreneur and CEO known for founding SpaceX and Tesla, leading innovations in electric vehicles and space exploration.\n",
      "- Known for his ambitious vision, including plans for Mars colonization and the development of sustainable energy solutions.\n",
      "\n",
      "- Visionary leader driving advancements in technology, renewable energy, and transportation through companies like Neuralink and The Boring Company.\n",
      "- Controversial figure due to his outspoken nature on social media and unconventional business practices, sparking both admiration and criticism.\n",
      "\n",
      "- Pioneering figure in the electric vehicle market with Tesla, significantly influencing the automotive industry towards sustainable practices.\n",
      "- Advocates for the development of artificial intelligence and space travel, promoting the idea of multi-planetary human existence.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "response1 = llm.invoke(\"tell me about elon musk in 2 bullet points\")\n",
    "print(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f7af416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Leela! How can I assist you today?\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. Therefore, I don't know your name. If you'd like, you can tell me your name!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke([HumanMessage(content=\"I am Leela\")])\n",
    "print(response.content)\n",
    "print(type(response))\n",
    "\n",
    "response2 = llm.invoke([HumanMessage(content=\"what is my name\")])\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d05211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Leela! How can I assist you today?\n",
      "Your name is Leela. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = []\n",
    "messages.append(HumanMessage(content=\"I am Leela\"))\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "messages.append(response)\n",
    "\n",
    "messages.append(HumanMessage(content=\"what is my name\"))\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa4acbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='I am Leela', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Leela! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 11, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C8zzfCzsLZ4VbphJY4JZEcX2xGNub', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--495d63d1-a8cc-4fde-9522-ae6eb3d5002c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 12, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60dc719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a funny AI. Give responses in funny way', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is 2 + 5?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "                    (\"system\", \"You are a funny AI. Give responses in funny way\"),\n",
    "                    (\"user\", \"{inputtext}\")\n",
    "                ])\n",
    "\n",
    "\n",
    "prompt_template.invoke({\n",
    "    \"inputtext\": \"what is 2 + 5?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07416fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 20, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C938p9DN5OTy7kNHLKG9LW3VMeiho', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f376f9e7-2ed4-428a-b33e-cdbb98dfe75f-0', usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Hindi\"),\n",
    "    HumanMessage(content=\"Hello!\")\n",
    "]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788eeaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b41f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e74966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system_message = \"Translate the following into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", system_message),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "chain.invoke({\n",
    "    \"language\": \"Chinese\",\n",
    "    \"text\": \"Hi\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ceda74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"Person\": {\"description\": \"Information about a person\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"The height of the personed expressed in meters\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Information about all people\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\\n```'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(..., description=\"The height of the personed expressed in meters\")\n",
    "    \n",
    "class People(BaseModel):\n",
    "    \"\"\"Information about all people\"\"\"\n",
    "    people: List[Person]\n",
    "    \n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d21231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Rishik', height_in_meters=1.8288), Person(name='Siva', height_in_meters=1.7374)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"Answer the user query. Wrap the output in json tags \\n {format_instructions}\"),\n",
    "    (\"user\", \"{query}\")\n",
    "]).partial(format_instructions = parser.get_format_instructions())\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "query = \"Rishik is 13 year old and he is 6 feet tall. Siva is 43 year old and 5.7 feet tall\" \n",
    "chain.invoke({\n",
    "   \"query\": query\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bb3866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"people\": [\\n    {\\n      \"name\": \"Rishik\",\\n      \"height_in_meters\": 1.8288\\n    },\\n    {\\n      \"name\": \"Siva\",\\n      \"height_in_meters\": 1.7374\\n    }\\n  ]\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 324, 'total_tokens': 388, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C94EiDcT3n6GsLMKb5JeciEOdzSI9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a316b600-b178-4a91-b45e-1891205bc643-0', usage_metadata={'input_tokens': 324, 'output_tokens': 64, 'total_tokens': 388, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\n",
    "   \"query\": query\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
