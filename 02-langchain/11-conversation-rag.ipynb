{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99629b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e737772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=\"letter.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af6af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10, separator=\"\")\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "vectorstore.save_local(\"faiss_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941d11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "message = \"\"\"\n",
    "            Answer this question using the provided context only.\n",
    "            If the information is not available in the context, justy reply with \"I dont know\"\n",
    "            {input}\n",
    "            Context: {context}\n",
    "          \"\"\"\n",
    "          \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", message)\n",
    "])    \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever_chain = create_retrieval_chain(vectorstore.as_retriever(), qa_chain)\n",
    "\n",
    "chat_history = []\n",
    "query = \"what is the person number of leela\"\n",
    "response = retriever_chain.invoke({\"input\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218a0b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The person number of Leela is 27353082.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1218dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=query),\n",
    "        AIMessage(content= response[\"answer\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "query2 = \"what is his title\"\n",
    "response2 = retriever_chain.invoke({\"input\": query2, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "627ea077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ac141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given above chat history and below latest user question\n",
    "    which might reference context in the chat history,\n",
    "    formulate a standalone question which can be understood\n",
    "    without the chat history. Do NOT answer the question,\n",
    "    just reformulate it if needed and otherwise return it as is.\n",
    "    Below is the latest question:\n",
    "    \n",
    "    {input}\n",
    "\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", contextualize_q_system_prompt)\n",
    "])\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "557e9a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ebd354d3-ba83-48e6-956a-b3c40f42b5cc', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2023-08-25T12:28:08+05:30', 'author': 'Suresh Babu', 'moddate': '2023-08-25T12:28:08+05:30', 'source': 'letter.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='1751752/A22 \\n \\n   \\n25-Aug-23 \\n \\n \\nFull Name  : Leela Prasad Jagu \\n \\nPerson No.  : 27353082 \\n \\n \\nTO W'),\n",
       " Document(id='bf708970-1632-42c5-8a4c-05366ca9601c', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2023-08-25T12:28:08+05:30', 'author': 'Suresh Babu', 'moddate': '2023-08-25T12:28:08+05:30', 'source': 'letter.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Ref: # 1751752/A2'),\n",
       " Document(id='da3dc87b-fe0c-4117-b1e2-4e55a697c299', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2023-08-25T12:28:08+05:30', 'author': 'Suresh Babu', 'moddate': '2023-08-25T12:28:08+05:30', 'source': 'letter.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='TO WHOMSOEVER IT MAY CONCERN \\n \\nThis is to certify that Leela Prasad Jagu has been working wit'),\n",
       " Document(id='51d34b20-2a04-4aa0-939c-b20a9a8652a4', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2023-08-25T12:28:08+05:30', 'author': 'Suresh Babu', 'moddate': '2023-08-25T12:28:08+05:30', 'source': 'letter.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='sident - Human Resources \\n \\n \\n \\nRegistered office address: \\nBuilding Number 5, Mind Space – Raheja I')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query3 = \"what is his title\"\n",
    "response3 = history_aware_retriever.invoke({\"input\": query3, \"chat_history\": chat_history})\n",
    "\n",
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f13ace2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Leela Prasad Jagu's last day is 21-Aug-23, close of business hours.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "system_prompt = \"\"\"You are assistant for question-answering tasks.\n",
    "    Answer this question using the provided context only. If you dont know the answer, just stay I don't know\n",
    "    context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever_chain = create_retrieval_chain(history_aware_retriever, qa_chain)\n",
    "\n",
    "query = \"when is his last day\"\n",
    "response = retriever_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac3317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
