{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391ab8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2ed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_by_one(number):\n",
    "    return number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950d33bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "r = RunnableLambda(increment_by_one)\n",
    "r.invoke(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10bd0b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "r = RunnableLambda(lambda x: x+1)\n",
    "r.invoke(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4e3fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
    "sequence.invoke(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f346946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 3\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": 2\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 4\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableParallel<mul_2,mul_5>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"mul_2\": 3,\n",
      "  \"mul_5\": 4\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mul_2': 3, 'mul_5': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rp = RunnableParallel(\n",
    "    {\n",
    "        \"mul_2\": RunnableLambda(lambda x: x * 2),\n",
    "        \"mul_5\": RunnableLambda(lambda x: x * 5)\n",
    "    }\n",
    ")\n",
    "\n",
    "rp.invoke(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01f5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mul_2': 4, 'mul_5': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = RunnableLambda(lambda x: x + 1) | {\n",
    "        \"mul_2\": RunnableLambda(lambda x: x + 2),\n",
    "        \"mul_5\": RunnableLambda(lambda x: x * 5)\n",
    "    }\n",
    "\n",
    "sequence.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c9f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': \"I found a well-priced lamp with extra storage for my bedroom, and despite a minor issue during transit, the company's responsive customer support quickly resolved it, indicating that Lumina is a caring and reliable brand.\",\n",
       " 'sentiment': 'The sentiment of the text is very positive. The reviewer expresses satisfaction with the lamp\\'s features, the swift delivery, effective customer service regarding issues, and an overall impression that the company values its customers. Phrases like \"happily sent over a new one,\" \"came within a few days,\" and \"great company that cares about their customers\" reflect a positive experience.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "review = f\"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had\n",
    "additional storage and not too high of a price point.\n",
    "Got it fast. The string to our lamp broke during the\n",
    "transit and the company happily sent over a new one.\n",
    "Came within a few days as well. It was easy to put\n",
    "together. I had a missing part, so I contacted their\n",
    "support and they very quickly got me the missing piece!\n",
    "Lumina seems to me to be a great company that cares\n",
    "about their customers and products!!\"\"\"\n",
    "\n",
    "summary_prompt = \"summarize the below text into one sentence: {text}\"\n",
    "sentiment_prompt = \"What is the sentiment of text below: {text}\"\n",
    "\n",
    "summary_prompt_template = PromptTemplate(template = summary_prompt)\n",
    "sentiment_prompt_template = PromptTemplate(template =  sentiment_prompt)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n",
    "summary_chain = summary_prompt_template | llm | StrOutputParser()\n",
    "sentiment_chain = sentiment_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "sequence = RunnableParallel({\n",
    "    \"summary\": summary_chain,\n",
    "    \"sentiment\": sentiment_chain\n",
    "})\n",
    "\n",
    "sequence.invoke({\n",
    "    \"text\": review\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b208fd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k1': 'v1', 'k2': 'v2'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    " \n",
    "rp = RunnablePassthrough()\n",
    "rp.invoke({\n",
    "    \"k1\": \"v1\",\n",
    "    \"k2\": \"v2\"\n",
    "}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce58c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': {'num': 3}, 'modified': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rp = RunnableParallel({\n",
    "    \"original\": RunnablePassthrough(),\n",
    "    \"modified\": lambda x: x[\"num\"] + 1\n",
    "})\n",
    "\n",
    "rp.invoke({\"num\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a20df38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePick\n",
    "\n",
    "rp = RunnablePick(\"k1\")\n",
    "rp.invoke({\n",
    "    \"k1\": \"v1\",\n",
    "    \"k2\": \"v2\"\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61dadcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 5, 'add_ten': 15}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableAssign\n",
    "\n",
    "mapper = {\n",
    "    \"add_ten\": lambda x: x[\"input\"] + 10    \n",
    "}\n",
    "\n",
    "ra = RunnableAssign(mapper)\n",
    "ra.invoke({\"input\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b28c864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k1': 'v1', 'k2': 'v2', 'd': {'k1': 'v1', 'k2': 'v2'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableAssign\n",
    "\n",
    "mapper = {\n",
    "    \"d\": RunnablePassthrough()\n",
    "}\n",
    "\n",
    "ra = RunnableAssign(mapper)\n",
    "ra.invoke({\"k1\": \"v1\", \"k2\": \"v2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c02b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
